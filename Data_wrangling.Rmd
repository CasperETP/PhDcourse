# Data wrangling and tidy data {#datawrangling}

![](cartoonscrubdata.jpg)

## Packages required

The following packages are required. If you need to go back and check how installing a package is done see the section 3.5(#installpackages).   

library(dplyr).  
library(ggplot2).  
library(readr).  
library(tidyr).  
library(broom).  
library(palmerpenguins).  


This chapter will introduce you to data wrangling with an emphasis on the ``` dplyr ``` package along with other helpful functions. You will see how powerful wrangling can be and how it can be like a magic wand to transform data into your specific needs. The key functions include but are not limited to:        




``` {r, echo =FALSE, results = 'hide',message = FALSE, warning = FALSE}
library(dplyr)
library(ggplot2)
library(readr) 
library(tidyr)  
library(broom)  
library(palmerpenguins)
my_df <- data.frame(names =c("Villy","Søren","Karl","Benny","Siri"),Grades= c(100,20,40,30,60))
my_df <- my_df %>% mutate(gender = c("boy","boy","boy","boy","girl"))
```

1. The overarching function which makes us able to combine functions and subsetting is **the pipe**. And what is a pipe? Pipes are a neat way to tie together several dataframes/functions into a chain of actions. It makes coding easier to understand and is therefore a better style of coding. It looks like this ```%>%```. For instance taking the mean of the first two rows of the ```my_df``` dataframe can be done like so:
``` my_df[1:2,"Grades"] %>% mean```. Learning to use the pipe to your advantage is learning to code. Luckily it all comes naturally when working with the following functions:


1. ``` left_join()``` merge two data frames together using a key column. This function (along with its cousin functions ``` right_join()``` and ```join() ``` etc.) is the bread and butter of working with many data types that needs to be merged and analysed. For example 
``` {r, echo =T, eval=T}
  library(dplyr) 
  my_data <- data.frame(
  names = c("Villy", "Søren", "Karl", "Benny", "Siri"),
  Grades = c(100, 20, 40, 30, 60),
  gender = c("boy", "boy", "boy", "boy", "girl")) 
  other_data <- data.frame(gender = c("boy", "girl"), description = c("Male", "Female"))
  left_joined_data <- left_join(my_data, other_data, by = "gender") 
  
  left_joined_data
```

1. ``` mutate() ``` construct/reconstruct a column using a newly defined column name. This function is useful to generate a new columns that modify existing ones often using a conditional to do so.  Now using the same data as above:
``` {r, echo =T, eval=T}
  mutated_data <- my_data %>%
  mutate(Grades_scaled = Grades / max(Grades))
``` 

1.  ``` glimpse() ``` take a sneak peak at a dataset. Useful for getting the dimensions of the data and the type of data contained in the columns. Now look at the newly constructed column
``` {r, echo =T, eval=T}
  glimpse(mutated_data)
``` 

1. ``` count() ``` counts the n of each unique value in a column. Usefull to combine with mutate to see the counts of the newly constructed column.

``` {r, echo =T, eval=T}
  counted_data <- count(my_data, gender)
  counted_data
``` 

1. ```arrange() ``` reorder the rows of a dataframe. For example, sort the rows of a dataset in descending order of the column height.   
``` {r, echo =T, eval=T}
arranged_data <- arrange(my_data, desc(Grades))
arranged_data
``` 
1.  ```select() ``` select columns using indexing or strings. e.g. ```my_df %>% select("names") ```.  

1. ```filter() ``` the rows of a dataframe based on a filter, e.g. thresholds. It is similar to the example shown in the introduction, where we used old school filtering on my_df dataframe ``` my_df[my_df$names %in% c("Karl","Villy"),]```. Using the filter function and pipes you can do it like this: ``` my_df %>% filter(names %in% c("Karl","Villy"))```.

1. ```summarise() ``` a dataframe using one or more of its columns/variables with a summary statistic. Such examples could be the median or the mean and an example look like this: ```my_df %>% summarise(mean = mean(Grades))```. This function can be very powerful when combined with the ```group_by``` function.

1. ``` group_by() ``` is a dplyr way of grouping rows, it is a way to assign different rows to a group and do statistical reporting on every specific group in the data set. An example require us to add a third column to ``` my_df ``` like this:
``` my_df <- my_df %>% mutate(gender = c("boy","boy","boy","boy","girl")) ```. Now using this new ```my_df``` we can ```group_by``` on the gender column and calculate the median on this group:

``` {r}  
my_df %>% 
  group_by(gender) %>% 
  summarise(median(Grades)) 
``` 

![](lter_penguins.png)

## Penguins!

Now we are going to use the functions described above on the penguin dataset. The data has been collected by [Dr. Kirstin Gorman](https://gormankb.github.io/) at the Palmer station, Antartica LTER. So real data collected for a purpose and published in a scientific journal.

```  library(palmerpenguins) ``` 

### Your turn - Look at the dataset
Now look at the dataset using  ``` glimpse() ``` in the console, now try to look at the dataset using
```str() ``` again you get information about the dataset. Please use one minute and compare the two methods to look at structure of the data.
Which one do you prefer and why?

Exercise 2.

1. You can input several grouping variables into ``` group_by(var1,var2) ```. Now use this information
to output the mean length of the flippers for species across islands, meaning for e.g. Adelie penguins
you will have three values. Remember that ``` mean``` can handle NA values in your dataset, you just have to tell it
to do so.

## More handy functions

Often, we are interested in a summary of information for many columns at once and thus we are not only looking at e.g. flipper_length across species and islands, but rather all measurements across species and islands. The reason to this more thorough data description is to gain better insight into the dataset. Better insights leads to better scientific questions.

1. ``` across() ``` is a function that makes it easy to transform/summarise multiple columns. It needs a *function* to apply to these columns, that could be ``` median ``` or ``` mean() ```. Also, it is often combined with functions like ```mutate()``` and ```summarise()``` to generate new columns using transformation on existing columns. Furthermore, it is also often combined with functions that informs ``` across() ``` on which columns to look at. For instance, ``` across() ``` can be combined with ``` starts_with() ``` and ```where()```.
OK enough text, now to an example that makes sense. Again looking at the penguins dataset, lets try to combine these functions to get an intuition about how they work together:

``` {r, eval=T, echo=T}
  penguins %>% 
  group_by(species,island) %>% 
  summarize(across(starts_with("bill"),~mean(., na.rm = TRUE)))
```

You can see that this gives a nice overview of the bill lengths across the species across the islands. One takeaway
one this would be that the difference in bill length seems less influenced by islands and more influenced by species.

## One way to deal with missing values

``` {r, eval=T, echo=T}
data <- penguins
sum(is.na(penguins))
```
The penguins dataset is not perfect. BUT, we can wave our magic data wand to impute the missing values. What is imputation? it is best-guess construction, meaning we already know a lot about the penguins so we fill in the missing values with guesses. It is not cheating, it is done all the time in research.

``` {r, eval=T, echo=T}

# rename the dataset so we can modify the data frame without having to reload the data
data <- penguins
# how many missing in the flipper length?
sum(is.na(data$flipper_length_mm))
```

Now - waving the magic data wand - we impute

``` {r, eval=T, echo=T}

# Impute missing values with mean imputation for the 'flipper_length_mm' column
data_imputed <- data %>%
  mutate(flipper_length_mm = ifelse(is.na(flipper_length_mm), 
                                    mean(flipper_length_mm, na.rm = TRUE), 
                                    flipper_length_mm))

```

What is going on? Here we are being aided by the 
``` ifelse ``` function which ask questions about the data, we pair this function with mutate and reconstruct the flipper_length_mm imputing missing values.

Typically though, we have a lot of variables that needs to be imputed and
*even though we hate to admit it, we know that we are lazy, and laziness is the super fuel of the efficient programmer!*
So below is a way to to the same, but instead of focusing on a specific column we use the
``` mutate_if ``` function to find all numeric columns in the dataset and do the same.

``` {r, eval=T, echo=T}
  # Impute missing values with mean imputation for numeric columns
  data_imputed <- data %>%
    mutate_if(is.numeric, ~ifelse(is.na(.), mean(., na.rm = TRUE), .))
```

### Your turn

Exercise 3.

Sometimes the variables you need impute are not just continuous variables like height or flipper length in mm. So what do we do then? Well, we guess, but instead of using the information in the column you want to impute, you use supplementary information in the adjacent columns. How can we do that? Well consider the column in the penguins data set which contains the gender of the penguins. We would not gain anything from replacing NA values with the mean of that column. In the natural world, species are often sexually dimorphic, which are fancy words for differences in size/color between sexes. We want to leverage this information to guess at the gender. So we can guess based on body size because we know sexes often differ in size. But first, we need to check if that is true for penguins. 

1.  So assuming you have the data set called **data_imputed** made above where all the continuous measurements have been mean imputed you can address the missing sex problem for the *Adelie* species.

Maybe you can learn something about sexual dimorphism from these plot and table?

``` {r, echo=T}
  table(is.na(data_imputed$sex),data_imputed$species)  

  ggplot(data_imputed %>% filter(species %in% "Adelie"), aes(x = body_mass_g, y = flipper_length_mm, color = sex)) +
  geom_point() +
  labs(title = "Body mass vs. flipper length by species")
  
```

``` {r, echo =F, eval =T}
 data_imputed_sex <- data_imputed %>%
    mutate(sex=ifelse(is.na(sex),
                      ifelse(body_mass_g < 3750 & flipper_length_mm <195, factor("female"),factor("male")) ,
                      sex ))

  #table(is.na(data_imputed_sex$sex),data_imputed_sex$species)  
```

## Back to the future

Lets play a little more with grouping in the penguins dataset. Lets try to ignore the missing values for now instead of imputing them.

### Get summary of a statistic, but grouping on another variable
``` {r, echo =T, eval =T}
penguins %>% 
  group_by(species) %>%
  summarize(
    mean_bm =mean(body_mass_g, na.rm=T),
    sd_bm   =sd(body_mass_g, na.rm=T),
    n            = n()
)
```
### Grouping on more than one variable
``` {r, echo =T, eval =T}
penguins %>% 
  group_by(species, sex) %>%
  summarize(
    mean_bm =mean(body_mass_g, na.rm=T),
    sd_bm   =sd(body_mass_g, na.rm=T),
    n            = n()
)
```
### Remove NAs sex variable and sort by mean body size
``` {r, echo =T, eval =T}
penguins %>% 
  filter(!is.na(sex)) %>% 
  group_by(species, sex) %>%
  summarize(
    mean_bm =mean(body_mass_g, na.rm=T),
    sd_bm   =sd(body_mass_g, na.rm=T),
    n            = n()
)%>% 
arrange(desc(mean_bm))
```

Great! That was the fast introduction to penguins. Think about what you learned from this. **The meta-information that 
you gather from doing exercises as the ones above is the real magic**. Therefore, as always, look at your data in different ways before diving in.

## Lets look at a dataset from the internet

Open this link in a new tab by copy-pasting and save it to your computer using right-click (https://raw.githubusercontent.com/zief0002/miniature-garbanzo/main/data/gapminder.csv). 
Save it as "gapminder2017".

### comma separated (csv)
try reading it in using read csv, the file ending is automatically put on there, so even though you did not name it gapminder2017.csv, that is the name it will get.
```{r, eval=T,echo=T}
# read csv can create in comma-separated files, read.table can be used to read in tab separated tables
# BUT in general, you just need to specify what separated your columns and if the data has a header
gapminder2017 <-read.csv("~/241023_phdcourse/data/gapminder2017.csv")

glimpse(gapminder2017)

```

Plotting is useful for understanding your data, in this case, we can plot the life expectancy and co2 across regions.
We will back to plotting much more so dont worry if you dont understand it all right now.
```{r, eval=T,echo=T}
ggplot(gapminder2017, aes(x = life_exp, y = co2, color = region)) +
  geom_point() +  # Add points for each data point
  geom_smooth(method = "lm", se = FALSE) +  # Add linear trendlines without confidence bands
  labs(title = "Life Expectancy vs. CO2 Levels across Regions (2017)", x = "CO2 Levels", y = "Life Expectancy")
```

However, what we want is not a point estimate for the year 2017, we want the change in life expectancy over time across regions, but not per year. We want to do it per 5 years to remove the uncertainty given by yearly measurements also we only want to look at the Nordic countries. The full dataset for gapminder is available in the R package ```gapminder``` install this if you have not done so already.

For an overview of the data, look at this plot
```{r, eval=T,echo=T}

library(gapminder)

# For Denmark see the trend in life expectancy
gapminder %>% filter(continent %in% "Europe") %>% 
  ggplot(., aes(x = year, y = lifeExp, color = country)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)  # Add linear trendlines without confidence bands
```

### Construct new date variable and look at life expectancy

Often, we are given raw data and we need to invent a new feature that incorporates the flaws of our data while still being useful. For example, yearly estimates might not be available and thus we want to contruct a 5 year period increase to remove some of uncertainty introduced by this effect.

```{r, eval=T,echo=T}
# Filter data for Nordic countries in the 'gapminder' dataset
nordic_countries <- c("Denmark", "Finland", "Iceland", "Norway", "Sweden")
nordic_data <- gapminder %>% filter(country %in% nordic_countries)

# Create a date interval of five years
nordic_data <- nordic_data %>%
  mutate(year_interval = year %/% 5 * 5)  # Create intervals of 5 years

# Summarize life expectancy for the Nordic countries within the 5-year intervals
summary <- nordic_data %>%
  group_by(country, year_interval) %>%
  summarise(avg_life_expectancy = mean(lifeExp, na.rm = TRUE))

# Show the summarized data
summary

ggplot(summary, aes(x = factor(year_interval), y = avg_life_expectancy, fill = country)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Life Expectancy of Nordic Countries by 5-Year Intervals", x = "Year Interval", y = "Average Life Expectancy") +
  scale_fill_brewer(palette = "Set1")  # Adjust the color palette as desired

```




### Your turn

Exercise 4.  

Now using the dataset **summary** we want to see how the percentwise increase between 1950 and year 2005 differs
between the Nordic countries

1. Create a new dataframe which contains the relative increase in life expectancy across Nordic countries between years and arrange from highest to lowest

```{r, eval=F,echo=F,message=F}
summary %>% 
  group_by(country) %>% 
  summarise(rel_dif = max(avg_life_expectancy)/min(avg_life_expectancy)*100 - 100) %>% 
  arrange(rel_dif)
```
